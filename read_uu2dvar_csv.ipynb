{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ecc886d9-1b4f-46a1-92d2-cdd9dd204b3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63c41b5-f91e-49f0-b025-49010107d8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyarrow import csv, parquet\\nimport os\\nimport pyarrow.parquet as pq\\n\\ndef parse_csvs():\\n    #Concatenates pandas by month\\n    monthly_li =  [\"%02d\" % i for i in range(1,11)]\\n    df_wbb = pd.DataFrame()\\n    for mon in monthly_li:\\n        t1 = datetime.now()\\n        df_jan = pd.read_csv(f\\'./df_{mon}.csv\\')\\n        #df_wbb = df_jan.loc[df_jan[\\'Station\\'] == \\'WBB\\']\\n        df_wbb = pd.concat([df_wbb,df_jan])\\n        t2 = datetime.now()\\n        took = t2 - t1\\n        print(f\"it took {took} seconds to parse month {mon}.\")\\n    df_wbb.shape\\n    return df_wbb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install pandas pyarrow\n",
    "#!pip install findspark\n",
    "#!pip install pyspark\n",
    "'''from pyarrow import csv, parquet\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def parse_csvs():\n",
    "    #Concatenates pandas by month\n",
    "    monthly_li =  [\"%02d\" % i for i in range(1,11)]\n",
    "    df_wbb = pd.DataFrame()\n",
    "    for mon in monthly_li:\n",
    "        t1 = datetime.now()\n",
    "        df_jan = pd.read_csv(f'./df_{mon}.csv')\n",
    "        #df_wbb = df_jan.loc[df_jan['Station'] == 'WBB']\n",
    "        df_wbb = pd.concat([df_wbb,df_jan])\n",
    "        t2 = datetime.now()\n",
    "        took = t2 - t1\n",
    "        print(f\"it took {took} seconds to parse month {mon}.\")\n",
    "    df_wbb.shape\n",
    "    return df_wbb'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e967777-fc8b-42a3-bc07-78d208ec7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_csv(\"./all_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ecc1931-77b7-4aa2-a14a-beebc9ecdb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q: can I fit all stations into 1km squre and have at least one neighboring station?\n",
    "#example = pd.read_csv('./df_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8250b-162b-404d-8da9-19156246c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for station in example['Station'].unique():\n",
    "    # Sometimes, columns rewrite as NaNs because they have different index - less values ..etc...\n",
    "    station_lat= example['Latitude'].loc[example['Station']==station].unique()\n",
    "    station_lon= example['Longitude'].loc[example['Station']==station].unique()\n",
    "    #stat = example.loc[['Station']=='HOL']\n",
    "    # + 0.013 is 1 km - lets make it 2 - 0.026\n",
    "    upper_lat = float(station_lat) + 0.013\n",
    "    upper_lon = float(station_lon) + 0.013\n",
    "    lower_lat = float(station_lat) - 0.013\n",
    "    lower_lon = float(station_lon) - 0.013\n",
    "    station_li= example['Station'].loc[(example['Latitude'].between(lower_lat,upper_lat)) & (example['Longitude'].between(lower_lon,upper_lon))].unique()\n",
    "    print(station, len(station_li))'''\n",
    "    #['HOL' 'CLK' 'OC1WX' 'D0231' 'E9449' 'UTOLY' 'UT224' 'PC023' 'UTTAY', 'G0195' 'CTBST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8973ed-27b4-441a-ab2a-f6532e1a5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example.set_index('(Index) -> Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be5ee3-dd32-41f3-beb9-805a858f18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET WINDOW AROUND STATION, create diff, shifts\n",
    "import matplotlib\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Define area of square 0.013 = 1 km2\n",
    "window = 0.026\n",
    "for station in example['Station'].unique():\n",
    "    station_lat= example['Latitude'].loc[example['Station']==station].unique()\n",
    "    station_lon= example['Longitude'].loc[example['Station']==station].unique()\n",
    "    #stat = example.loc[['Station']=='HOL']\n",
    "    # + 0.013 is 1 km - lets make it 2 - 0.026\n",
    "    upper_lat = float(station_lat) + window\n",
    "    upper_lon = float(station_lon) + window\n",
    "    lower_lat = float(station_lat) - window\n",
    "    lower_lon = float(station_lon) - window\n",
    "    station_li= example['Station'].loc[(example['Latitude'].between(lower_lat,upper_lat)) & (example['Longitude'].between(lower_lon,upper_lon))].unique()\n",
    "    print(f'{station} station has  {len(station_li)} neighbors.')\n",
    "    reg_df = pd.DataFrame()\n",
    "    for neighb in station_li:\n",
    "        t_st = example['yo_t'].loc[example['Station']==neighb]\n",
    "        reg_df[str(neighb)] = t_st\n",
    "    \n",
    "    tes_val = station\n",
    "    predictors = reg_df.keys()\n",
    "    #predictors = predictors.drop(tar_val)\n",
    "    prep_df = reg_df[predictors].dropna()\n",
    "    a = [-9999]\n",
    "    prep_df = prep_df[~prep_df[predictors].isin(a)]\n",
    "    X = prep_df.drop([tes_val],axis=1)\n",
    "    y = prep_df[tes_val]\n",
    "    if X.shape[0] < 48:\n",
    "        pass\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "        print(\"Splitting dataset complete!\")\n",
    "        print(\"-\"*30)\n",
    "        try:\n",
    "            BR = linear_model.BayesianRidge()\n",
    "            BR.fit(X_train,y_train)\n",
    "            print(\"Training complete!\")\n",
    "            print(\"-\"*30)\n",
    "            plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "            preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "            preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "            preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "            descr = preds.describe()\n",
    "            print(f'For {station} matrix is:')\n",
    "            print(descr)\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2804265-bc90-4cfe-b63f-dd41ac51f7df",
   "metadata": {},
   "source": [
    "reg_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6fbca3-8630-4db2-aa72-b189ee7ed02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset complete!\n",
      "------------------------------\n",
      "Training complete!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Do Bayes Regres Ridge without changes for one month!\n",
    "import matplotlib\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "tes_val = 'SOLSM'\n",
    "predictors = reg_df.keys()\n",
    "#predictors = predictors.drop(tar_val)\n",
    "prep_df = reg_df[predictors].dropna()\n",
    "X = prep_df.drop([tes_val],axis=1)\n",
    "y = prep_df[tes_val]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "print(\"Splitting dataset complete!\")\n",
    "print(\"-\"*30)\n",
    "BR = linear_model.BayesianRidge()\n",
    "BR.fit(X_train,y_train)\n",
    "print(\"Training complete!\")\n",
    "print(\"-\"*30)\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e13a171e-5d4f-4521-ac47-20e6cb8d637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>true</th>\n",
       "      <th>residuals</th>\n",
       "      <th>abs_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1083.000000</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>1083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018525</td>\n",
       "      <td>-0.044940</td>\n",
       "      <td>-0.063465</td>\n",
       "      <td>0.831582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.699421</td>\n",
       "      <td>1.286027</td>\n",
       "      <td>1.095757</td>\n",
       "      <td>0.715924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.995683</td>\n",
       "      <td>-3.290000</td>\n",
       "      <td>-3.794209</td>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.481906</td>\n",
       "      <td>-0.920000</td>\n",
       "      <td>-0.743554</td>\n",
       "      <td>0.293335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.008111</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>-0.069589</td>\n",
       "      <td>0.645145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.489346</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.521906</td>\n",
       "      <td>1.178632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.651983</td>\n",
       "      <td>6.030000</td>\n",
       "      <td>4.565034</td>\n",
       "      <td>4.565034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preds         true    residuals      abs_res\n",
       "count  1083.000000  1083.000000  1083.000000  1083.000000\n",
       "mean      0.018525    -0.044940    -0.063465     0.831582\n",
       "std       0.699421     1.286027     1.095757     0.715924\n",
       "min      -1.995683    -3.290000    -3.794209     0.003483\n",
       "25%      -0.481906    -0.920000    -0.743554     0.293335\n",
       "50%      -0.008111    -0.170000    -0.069589     0.645145\n",
       "75%       0.489346     0.720000     0.521906     1.178632\n",
       "max       2.651983     6.030000     4.565034     4.565034"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f98c9e8-d71e-4a0e-b079-13566103e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def create_shifts(df,periods,column_name_li):\n",
    "  #Creates shifts in periods for dataframe and names i.e. what is value in previous one or two terms?\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"sh_\" + str(periods)] = df[name_li].shift(periods = periods)\n",
    "    return df\n",
    "\n",
    "def create_differences(df,periods,column_name_li):\n",
    "    # Yields a lot of warnings - figure it out\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"dif_\" + str(periods)] = df[name_li].diff(periods = periods)\n",
    "    return df\n",
    "\n",
    "######################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997afa3-f0cf-4c4c-8756-837ee6c65f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f099c6-ae1f-4be3-800a-9a9c6d7b1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_val = 'SOLSM'\n",
    "def reg_neig_station(df,station,tes_val):\n",
    "    df_wbb2 = df\n",
    "    \n",
    "    #gernerate list of interesting features\n",
    "    df_wbb2 = df_wbb2.loc[df_wbb2[tes_val] != -9999]\n",
    "    nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "    feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "    df1 = df_wbb2[feat_to_plot]\n",
    "    for tm_sp in [1,2]:\n",
    "        df_wbb2 = create_shifts(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "    for tm_sp in [1,2]:\n",
    "        df_wbb2 = create_differences(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "    dif_li = [tes_val+'dif_'+str(n) for n in [1,2]]\n",
    "    sh_li = [tes_val+'sh_'+str(n) for n in [1,2]]\n",
    "    feat_li = [tes_val] + dif_li+sh_li\n",
    "    prep_df = df_wbb2[feat_li].dropna()\n",
    "    if prep_df.shape[0] < 23:\n",
    "        a = \"Not enough data in {} station dataset\".format(station)\n",
    "    else:\n",
    "        X = prep_df.drop([tes_val],axis=1)\n",
    "        y = prep_df[tes_val]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "        print(\"Splitting dataset complete!\")\n",
    "        print(\"-\"*30)\n",
    "        BR = linear_model.BayesianRidge()\n",
    "        BR.fit(X_train,y_train)\n",
    "        print(\"Training complete!\")\n",
    "        print(\"-\"*30)\n",
    "        plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "        preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "        preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "        preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "        a = preds.describe()\n",
    "        print(station)\n",
    "        print(\"-\"*30)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ae5d8e-1b99-46fb-9f6f-5eecc3c6de4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SOL', 'SOLSM', 'SOLAP', 'SOLHP', 'SOLsh_1', 'SOLSMsh_1', 'SOLAPsh_1',\n",
       "       'SOLHPsh_1', 'SOLsh_2', 'SOLSMsh_2',\n",
       "       ...\n",
       "       'SOLAPsh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLHPsh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLsh_1sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLSMsh_1sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLAPsh_1sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLHPsh_1sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLsh_2sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLSMsh_2sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLAPsh_2sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4',\n",
       "       'SOLHPsh_2sh_3sh_4dif_1dif_3dif_4dif_5sh_1sh_2sh_3sh_4'],\n",
       "      dtype='object', length=65084)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " reg_df.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71e96f50-5a61-455a-b1f2-a7d8c3b21c19",
   "metadata": {},
   "source": [
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabea68-f890-46df-b415-c36156e982f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def create_shifts(df,periods,column_name_li):\n",
    "  #Creates shifts in periods for dataframe and names i.e. what is value in previous one or two terms?\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"sh_\" + str(periods)] = df[name_li].shift(periods = periods)\n",
    "    return df\n",
    "\n",
    "def create_differences(df,periods,column_name_li):\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"dif_\" + str(periods)] = df[name_li].diff(periods = periods)\n",
    "    return df\n",
    "\n",
    "######################\n",
    "def get_acc_for_station(df,station,tes_val):\n",
    "    df_wbb2 = df\n",
    "    #gernerate list of interesting features\n",
    "    feat_li = ['yo_', 'd_', 'xb_', 'xa_', 'stdev_']\n",
    "    feat2_li = ['t','td','u','v','ws','rh'] \n",
    "    df_wbb2 = df_wbb2.loc[df_wbb2[tes_val] != -9999]\n",
    "    nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "    feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "    df1 = df_wbb2[feat_to_plot]\n",
    "    for tm_sp in [1,2,3,4,5]:\n",
    "        df_wbb2 = create_shifts(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "    for tm_sp in [1,2,3,4,5]:\n",
    "        df_wbb2 = create_differences(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "    dif_li = [tes_val+'dif_'+str(n) for n in [1,2,3,4,5]]\n",
    "    sh_li = [tes_val+'sh_'+str(n) for n in [1,2,3,4,5]]\n",
    "    feat_li = [tes_val] + dif_li+sh_li\n",
    "    prep_df = df_wbb2[feat_li].dropna()\n",
    "    if prep_df.shape[0] < 23:\n",
    "        a = \"Not enough data in {} station dataset\".format(station)\n",
    "    else:\n",
    "        X = prep_df.drop([tes_val],axis=1)\n",
    "        y = prep_df[tes_val]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "        print(\"Splitting dataset complete!\")\n",
    "        print(\"-\"*30)\n",
    "        BR = linear_model.BayesianRidge()\n",
    "        BR.fit(X_train,y_train)\n",
    "        print(\"Training complete!\")\n",
    "        print(\"-\"*30)\n",
    "        plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "        preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "        preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "        preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "        a = preds.describe()\n",
    "        print(station)\n",
    "        print(\"-\"*30)\n",
    "    return a\n",
    "\n",
    "#df_one = df_wbb.loc[df_jan['Station'] == 'HOL']\n",
    "\n",
    "import matplotlib\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "#gernerate list of interesting features\n",
    "feat_li = ['yo_', 'd_', 'xb_', 'xa_', 'stdev_']\n",
    "feat2_li = ['t','td','u','v','ws','rh'] \n",
    "nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "df1 = df_wbb[feat_to_plot]\n",
    "\n",
    "\n",
    "for stat in df_wbb['Station'].unique():\n",
    "    df_one = df_wbb.loc[df_wbb['Station'] ==stat]\n",
    "    for tm_sp in [1,2,3,4,5]:\n",
    "        df_one = create_shifts(df_one, tm_sp, df1.keys())\n",
    "\n",
    "    for tm_sp in [1,2,3,4,5]:\n",
    "        df_one = create_differences(df_one, tm_sp, df1.keys())\n",
    "    \n",
    "    z = get_acc_for_station(df_one,stat,'d_ws')\n",
    "    print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5173396d-b81a-4b58-85cd-24a0b6637627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_wbb['Station'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be6e462a-a080-4115-8b47-7ce202f80739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering 06\n",
      "it took 0:02:37.083232 seconds to parse 06 month.\n",
      "Filtering 07\n",
      "it took 0:03:17.384173 seconds to parse 07 month.\n",
      "Filtering 08\n",
      "it took 0:03:36.063589 seconds to parse 08 month.\n",
      "Filtering 09\n",
      "it took 0:03:30.762207 seconds to parse 09 month.\n",
      "Filtering 10\n",
      "it took 0:03:34.102924 seconds to parse 10 month.\n",
      "Filtering 11\n",
      "it took 0:00:03.415067 seconds to parse 11 month.\n"
     ]
    }
   ],
   "source": [
    "# Python version is 3.9.13 so I can use pyarrow\n",
    "monthly_li =  [\"%02d\" % i for i in range(6,12)]\n",
    "for mon in monthly_li:\n",
    "    print(f\"Filtering {mon}\")\n",
    "    t1 = datetime.now()\n",
    "    path = f\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022{mon}*.csv\"\n",
    "    filenames = glob.glob(path)\n",
    "    df_wbb_JAN = pd.DataFrame()\n",
    "    for filename in filenames:\n",
    "        df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "        df1 = df[(df.Latitude<41.34) & (df.Latitude > 40.17) & (df.Longitude < -111.346) & (df.Longitude > -112.678)]\n",
    "        df_wbb_JAN=pd.concat([df_wbb_JAN,df1])\n",
    "    t2 = datetime.now()\n",
    "    took = t2 - t1\n",
    "    print(f\"it took {took} seconds to parse {mon} month.\")\n",
    "    df_wbb_JAN.to_csv(f'./df_{mon}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9a010-4f9d-4b7b-8240-bdbb6486c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dat_for_coordinates(months_start,months_end,lat1 = 41.34,lat2 = 40.17 ,lon1 = -111.346,lon2 = -112.678):\n",
    "\tmonthly_li =  [\"%02d\" % i for i in range(months_start,months_end)] # generates list of months in string format ’01’, ’02’…\n",
    "\tfor mon in monthly_li:\n",
    "    \t\tprint(f\"Filtering {mon}\")\n",
    "    \t\tt1 = datetime.now()\n",
    "    \t\tpath = f\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022{mon}*.csv\"\n",
    "    \t\tfilenames = glob.glob(path)\n",
    "    \t\tdf_wbb_mon = pd.DataFrame()\n",
    "    \tfor filename in filenames:\n",
    "        \t\tdf= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "        \t\tdf1 = df[(df.Latitude< lat1) & (df.Latitude > lat2) & (df.Longitude < lon1) & (df.Longitude > lon2)]\n",
    "        \t\tdf_wbb_mon=pd.concat([df_wbb_mon,df1])\n",
    "    \tt2 = datetime.now()\n",
    "    \ttook = t2 - t1\n",
    "    \tprint(f\"it took {took} seconds to parse {mon} month.\")\n",
    "    \tdf_wbb_mon.to_csv(f'./df_{mon}.csv')\n",
    "return df_wbb_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fb02c-32cf-4670-b12d-2a165112dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\"\"\"li_files = []\n",
    "for file_name in os.listdir('./Parquets'):\n",
    "    li_files.append(file_name)\"\"\"\n",
    "\n",
    "table = pq.read_table(f'./Parquets/2022030813.parquet', filters=[('Latitude', '>', 40.17),('Latitude', '<', 41.34),('Longitude', '>', -112.678),('Longitude', '<', -111.346)])\n",
    "\n",
    "#for nam in li_files[1:30]:\n",
    "#    table = pq.read_table(f'./Parquets/{filename}', filters=[('Station', '==', 'WBB'),])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ebc680c-589f-4a30-bb7d-2d8e45c662af",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('./combined.parquet_FEB', filters=[('Station', '==', 'WBB')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "757cab68-3bec-4762-9e56-f55b5f3ca263",
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "682ee84a-ffc2-4765-81d9-f8c29152ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_data_frame_to_parquet(local_file: str, parquet_file: str) -> None:\n",
    "    table = csv.read_csv(local_file)\n",
    "    parquet.write_table(table, parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ecd5f-5300-4cfe-8ade-8307d63f5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_parquet_files2(input_folder, target_path,i,j):\n",
    "    try:\n",
    "        files = []\n",
    "        for file_name in os.listdir(input_folder)[i:j]:\n",
    "            files.append(pq.read_table(os.path.join(input_folder, file_name)))\n",
    "        with pq.ParquetWriter(target_path,\n",
    "                files[0].schema,\n",
    "                version='2.0',\n",
    "                compression='gzip',\n",
    "                use_dictionary=True,\n",
    "                data_page_size=2097152, #2MB\n",
    "                write_statistics=True) as writer:\n",
    "            for f in files:\n",
    "                writer.write_table(f)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07e479-1cef-41df-abed-0c6505717bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,300,30):\n",
    "    j = i+30\n",
    "    combine_parquet_files2('./Parq_mon/', f'./Parq_big/combined{i}.parquet',i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8ff9e85-1484-456b-a271-31c0b9b4892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('./Parq_big/combined180.parquet', filters=[('Station', '==', 'HOL')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c2b24c2-92d4-43fb-8740-55be4cfce6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e496d6f5-79c8-4644-bf19-619e7855437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 67)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hol_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "303cce6d-b205-4f6e-8b86-5456ee5d9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idx = [30,60,90,120,150,180]\n",
    "HOL_df = pd.DataFrame()\n",
    "for i in idx:\n",
    "    table = pq.read_table(f'./Parq_big/combined{i}.parquet', filters=[('Station', '==', 'WBB')])\n",
    "    #table1 = pa.concat_tables([table1,table])\n",
    "    hol_df = table.to_pandas()\n",
    "    HOL_df = pd.concat([HOL_df, hol_df])\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86f9e013-9c84-43fc-94eb-d6d6d09e7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOL_df.to_csv('WBB_parq_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68a31cb9-a0cd-4a06-ba6f-e800d88c0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOL_df['yo_t'] = HOL_df['yo_t'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c9f3e12-c7ef-4add-b4dc-dd2ef7eadcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HOL_df['yo_t'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc859e8-afa8-4fd2-9255-14d96fa96975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"test/Parquets/2022010100.parquet\"\n",
    "\n",
    "for i in range(31):\n",
    "    num = \"%02d\" % i\n",
    "days = [\"%02d\" % i for i in range(32)]\n",
    "print(days)\n",
    "import re\n",
    "for month in ['01','02','03']:\n",
    "    file_nam = './Pa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23aae29-cd0c-4eff-bdca-274de03c5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "'''spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "df=spark.read.option(\"header\",True) \\\n",
    "        .csv(\"./combined.parquet\")\n",
    "df.printSchema()'''\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "df=spark.read.option(\"header\",True) \\\n",
    "        .csv(\"./combined.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf0ab1-e5de-449e-b5f1-a7441ad65fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_pandas()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d74b31-48e3-43b2-97b6-9c0c2cd4708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_for_station(station):\n",
    "    for filename in filenames:\n",
    "    df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "    df1 = df[df.Station=='WBB']\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f67032-5a43-497c-9423-2019a8301c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version is 3.9.13 so I can use pyarrow\n",
    "filenames = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022*.csv\")\n",
    "#li_st = ['HOL', 'SNI', 'SBE', 'SB2','PCB', 'PCT', 'SNV' ,'MBY', 'DVE']\n",
    "li_st = ['SNI', 'SBE', 'SB2','PCB', 'PCT', 'SNV' ,'MBY', 'DVE']\n",
    "print(len(filenames))\n",
    "'''for filename in filenames:\n",
    "    df = pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1], engine=\"pyarrow\")\n",
    "    df.to_parquet(\"./{}.parquet\".format(filename), compression=None)'''\n",
    "\n",
    "'''for station in li_st:\n",
    "    df_wbb = pd.DataFrame()\n",
    "    for filename in filenames:\n",
    "        df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1], engine=\"pyarrow\")\n",
    "        df1 = df[df.Station==station]\n",
    "#       display(df1)\n",
    "        df_wbb=pd.concat([df_wbb,df1])\n",
    "    df_wbb.to_csv('./'+station+'2022.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb16da7-e8d6-4aa6-9170-09c7be131a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fea01-eacf-4111-8595-aa9f0ca0ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to get understand values of differences\n",
    "def create_shifts(df,periods,column_name_li):\n",
    "  #Creates shifts in periods for dataframe and names i.e. what is value in previous one or two terms?\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"sh_\" + str(periods)] = df[name_li].shift(periods = periods)\n",
    "    return df\n",
    "\n",
    "def create_differences(df,periods,column_name_li):\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"dif_\" + str(periods)] = df[name_li].diff(periods = periods)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8889cf-1071-4ff4-b10a-e43587641eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data file names      \n",
    "'''filenames = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/20220101*.csv\")\n",
    "#print(filenames)\n",
    "df_wbb = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "    df1 = df[df.Station=='WBB']\n",
    "#    display(df1)\n",
    "    df_wbb=pd.concat([df_wbb,df1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b7fff-3648-480f-a033-aa0108c57978",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filenames = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022*.csv\")\n",
    "li_st = ['WBB' 'HOL' 'SNI' 'SBE' 'SB2' 'PCB' 'PCT' 'SNV' 'MBY' 'DVE']\n",
    "for filename in filenames:\n",
    "    df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "    df1 = df['Station'].unique()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051fb60-75f0-4ccf-b59b-11240fca66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022*.csv\")\n",
    "#print(filenames)\n",
    "'''df_wbb = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "    df1 = df[df.Station=='PCB']\n",
    "#    display(df1)\n",
    "    df_wbb=pd.concat([df_wbb,df1])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11020a-0d51-4613-9e93-9aa4ff074874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing cell\n",
    "#df_wbb2022 = pd.read_csv(\"./wbb_2022.csv\")\n",
    "\n",
    "df_wbb2 = df_wbb\n",
    "if df_wbb2.shape[0] < 10:\n",
    "    print(\"Not enough data\")\n",
    "    \n",
    "print(df_wbb2.shape)\n",
    "df_wbb2 = df_wbb2.loc[df_wbb2['d_u'] != -9999]\n",
    "print(df_wbb2.shape)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "#gernerate list of interesting features\n",
    "feat_li = ['yo_', 'd_', 'xb_', 'xa_', 'stdev_']\n",
    "feat2_li = ['t','td','u','v','ws','rh'] \n",
    "nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "df1 = df_wbb2[feat_to_plot]\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "        df_wbb2 = create_shifts(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "        df_wbb2 = create_differences(df_wbb2, tm_sp, df1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96b3f3-2f65-4a43-bde0-ba7f8549bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "station = 'WBB'\n",
    "tes_val = \"d_t\"\n",
    "dif_li = [tes_val+'dif_'+str(n) for n in [1,2,3,4,5]]\n",
    "sh_li = [tes_val+'sh_'+str(n) for n in [1,2,3,4,5]]\n",
    "feat_li = [tes_val] + dif_li+sh_li\n",
    "print(feat_li)\n",
    "print(df_wbb2.keys())\n",
    "prep_df = df_wbb2[feat_li].dropna()\n",
    "X = prep_df.drop([tes_val],axis=1)\n",
    "y = prep_df[tes_val]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 42)\n",
    "print(\"Splitting dataset complete!\")\n",
    "    \n",
    "BR = linear_model.BayesianRidge()\n",
    "BR.fit(X_train,y_train)\n",
    "print(\"Training complete!\")\n",
    "   \n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "a = preds.describe()\n",
    "print(station)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f92af2-c63c-4bcf-9d0a-0166457cfddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b44995-09f1-4678-aa4a-7f292d560f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022*.csv\")\n",
    "# https://pythonspeed.com/articles/pandas-read-csv-fast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380d8ad-2b17-4c6c-9755-7e705e301948",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Opravit -rozdelit na zvlastni dve funkce\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_acc_for_station(df,station,tes_val):\n",
    "    df_wbb2 = df\n",
    "    #gernerate list of interesting features\n",
    "    feat_li = ['yo_', 'd_', 'xb_', 'xa_', 'stdev_']\n",
    "    feat2_li = ['t','td','u','v','ws','rh'] \n",
    "    df_wbb2 = df_wbb2.loc[df_wbb2[tes_val] != -9999]\n",
    "    nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "    feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "    df1 = df_wbb2[feat_to_plot]\n",
    "    for tm_sp in [1,2,3,4,5]:\n",
    "        df_wbb2 = create_shifts(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "    for tm_sp in [1,2,3,4,5]:\n",
    "        df_wbb2 = create_differences(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "    dif_li = [tes_val+'dif_'+str(n) for n in [1,2,3,4,5]]\n",
    "    sh_li = [tes_val+'sh_'+str(n) for n in [1,2,3,4,5]]\n",
    "    feat_li = [tes_val] + dif_li+sh_li\n",
    "    prep_df = df_wbb2[feat_li].dropna()\n",
    "    if prep_df.shape[0] < 23:\n",
    "        a = \"Not enough data in {} station dataset\".format(station)\n",
    "    else:\n",
    "        X = prep_df.drop([tes_val],axis=1)\n",
    "        y = prep_df[tes_val]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "        print(\"Splitting dataset complete!\")\n",
    "        print(\"-\"*30)\n",
    "        BR = linear_model.BayesianRidge()\n",
    "        BR.fit(X_train,y_train)\n",
    "        print(\"Training complete!\")\n",
    "        print(\"-\"*30)\n",
    "        plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "        preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "        preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "        preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "        a = preds.describe()\n",
    "        print(station)\n",
    "        print(\"-\"*30)\n",
    "    return a\n",
    "\n",
    "li_st = ['WBB', 'HOL', 'SNI', 'SBE', 'SB2','PCB', 'PCT', 'SNV' ,'MBY', 'DVE']\n",
    "#print(filenames)\n",
    "for station in li_st:\n",
    "    df_wbb = pd.DataFrame()\n",
    "    for filename in filenames:\n",
    "        df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "        df1 = df[df.Station==station]\n",
    "#       display(df1)\n",
    "        df_wbb=pd.concat([df_wbb,df1])\n",
    "    z = get_acc_for_station(df_wbb,station,'d_td')\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba790cdb-b00d-4272-a992-631a6c1394ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 minutes WBB - 4 cores 10:41 - 11:09 for January 2022, 10 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb27ea5-74e5-43f1-aacd-4e289f947bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data file names2\n",
    "# for next analysis use 2022!!!!!\n",
    "\n",
    "'''filenames2 = glob.glob(\"/uufs/chpc.utah.edu/common/home/u0035056/uu2dvar/csv/2022**.csv\")\n",
    "print(len(filenames2))\n",
    "df_wbb2 = pd.DataFrame()\n",
    "for filename in filenames2:\n",
    "    df= pd.read_csv(filename, delimiter=',',index_col=0,header=0,skiprows=[1])\n",
    "    df1 = df[df.Station=='WBB']\n",
    "#    display(df1)\n",
    "    df_wbb2=pd.concat([df_wbb2,df1])'''\n",
    "    \n",
    "#df_wbb2.to_csv(\"./wbb_740_2021months.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8306537-7340-46e4-af49-f809ab0ee182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2022 = pd.read_csv(\"./wbb_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b7cf1-1f66-4368-a8e6-8354f9051f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2 = df_wbb2022\n",
    "print(df_wbb2.shape)\n",
    "df_wbb2 = df_wbb2.loc[df_wbb2['d_u'] != -9999]\n",
    "print(df_wbb2.shape)\n",
    "#gernerate list of interesting features\n",
    "feat_li = ['yo_', 'd_', 'xb_', 'xa_', 'stdev_']\n",
    "feat2_li = ['t','td','u','v','ws','rh'] \n",
    "nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "print(feat_to_plot)\n",
    "df1 = df_wbb2[feat_to_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95048fd-3988-48df-80d0-287bea93c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating shifts and differences only from ['d_t', 'd_td', 'd_u', 'd_v', 'd_ws', 'd_rh']\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "      df_wbb2 = create_shifts(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "      df_wbb2 = create_differences(df_wbb2, tm_sp, df1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f05ee5-ad85-4de5-9420-635164b1a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2[['d_t', 'd_tdif_1', 'd_tdif_2', 'd_tdif_3', 'd_tdif_4', 'd_tdif_5', 'd_tsh_1', 'd_tsh_2', 'd_tsh_3', 'd_tsh_4', 'd_tsh_5']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e2f1d-f707-4823-a3ad-39ec9fd79fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2['ok2'] = np.where(df_wbb2['d_t']==df_wbb2['d_tsh_2'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776a807-f01c-40ae-9356-255c2f903c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremes\n",
    "def get_larger_boxplot_preceding(df,column,err_val):\n",
    "    '''shows boxplot of chosen column when absolute value is Larger than err_val'''\n",
    "    no_err = df.loc[abs(df[column]) > err_val]\n",
    "    feature_set = [column,column + 'sh_1',column +'sh_2',column +'sh_3',column +'sh_4']\n",
    "    a = no_err[feature_set].boxplot()\n",
    "    return a\n",
    "\n",
    "get_larger_boxplot_preceding(df_wbb2, 'd_rh', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6376b-39dd-4e98-8cc8-6fb8a230af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tes_val = 'd_rh'\n",
    "dif_li = [tes_val+'dif_'+str(n) for n in [1,2,3,4,5]]\n",
    "sh_li = [tes_val+'sh_'+str(n) for n in [1,2,3,4,5]]\n",
    "feat_li = [tes_val] + dif_li+sh_li\n",
    "print(feat_li)\n",
    "prep_df = df_wbb2[feat_li].dropna()\n",
    "X = prep_df.drop([tes_val],axis=1)\n",
    "y = prep_df[tes_val]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3cb22-e945-4b3c-9c78-13cb69fa864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17597b5b-37ab-498b-b555-7207dbd04a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "BR = linear_model.BayesianRidge()\n",
    "BR.fit(X_train,y_train)\n",
    "y_predBRL = BR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eefac1-411d-4d13-b7bc-292e43dc7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pl = BR.predict(X_test)\n",
    "y_pl = y_test\n",
    "#minmaxscaler - use original data a neco vyleze, vlastne je jedno co to ted bude\n",
    "plt.scatter(X_pl, y_predBRL)\n",
    "plt.scatter(y_test, BR.predict(X_test))\n",
    "plt.xlabel('ValFrom Dataset')\n",
    "plt.ylabel('Val Predicted By Model')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6) # Custom figure size in inches\n",
    "plt.title(\"OBS Dataset Vs  Predicted By Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf31f2b-de81-4038-9992-1c62916fc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":BR.predict(X_test), \"true\":y_test})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in Bayesian Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31c7b4-98cf-4e1a-be95-12bc1515b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d35c1-6e12-4d20-b04d-0552dc780f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cff3c-ba2a-48f4-bc6e-cece1eebe9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbbJAN= pd.read_csv(\"./wbb_740_2021months.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443dd50-528d-4462-a714-94f126086cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tm_sp in [1,2,3,4,5]:\n",
    "      df_wbbJAN = create_shifts(df_wbbJAN, tm_sp, df1.keys())\n",
    "\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "      df_wbbJAN = create_differences(df_wbbJAN, tm_sp, df1.keys())\n",
    "\n",
    "tes_val = 'd_rh'\n",
    "dif_li = [tes_val+'dif_'+str(n) for n in [1,2,3,4,5]]\n",
    "sh_li = [tes_val+'sh_'+str(n) for n in [1,2,3,4,5]]\n",
    "feat_li = [tes_val] + dif_li+sh_li\n",
    "print(feat_li)\n",
    "prep_df = df_wbbJAN[feat_li].dropna()\n",
    "X = prep_df.drop([tes_val],axis=1)\n",
    "y = prep_df[tes_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc83f00-dedc-408b-a618-736fb448eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":BR.predict(X), \"true\":y})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in Bayesian Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e5a19-d9b3-4839-a901-b6fd0345aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"abs_res\"] = preds['residuals'].apply(lambda x: abs(x))\n",
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aec19d-a18a-4e82-9f77-468a581261ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['ape']= (preds['residuals']/preds['true'])*100\n",
    "print(preds['ape'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0868851-7261-404f-a95c-5d10f3f78436",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523617c-c11d-4c49-8fe2-e74411469d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install regressormetricgraphplot\n",
    "#!pip install xgboost\n",
    "#!pip install gplearn\n",
    "def show_linear_comparison(X_train,X_test,y_train,y_test):\n",
    "    # Fitting training set to linear regression model\n",
    "    from regressormetricgraphplot import CompareModels\n",
    "    plot = CompareModels()\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression(n_jobs=-1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_predlr = lr.predict(X_test)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rfr = RandomForestRegressor(n_estimators=10, random_state=10, n_jobs=-1)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_predrf = rfr.predict(X_test)\n",
    "    plot.add(model_name='Linear Regression', y_test=y_test, y_pred=y_predlr)\n",
    "    \n",
    "    from regressormetricgraphplot import CompareModels\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predlr)\n",
    "    \n",
    "    \n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predrf)\n",
    "    plot.add('Random Forest', y_test, y_predrf)\n",
    "    \n",
    "    # Fitting XGBoost to the dataset  (reg:squarederror)\n",
    "    '''from xgboost import XGBRegressor\n",
    "    xgb = XGBRegressor(n_jobs=4, silent=False, objective='reg:linear',\n",
    "                   max_depth=3, random_state=10, n_estimators=100,\n",
    "                   learning_rate=0.3, verbose=True)\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    y_predXGB = xgb.predict(X_test)\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predXGB)\n",
    "    plot.add('XGBoost', y_test, y_predXGB)\n",
    "    \n",
    "    # Fitting training set to voting regression model\n",
    "    from sklearn.ensemble import VotingRegressor\n",
    "    vr = VotingRegressor(estimators=[('LinReg', lr),\n",
    "                                 ('RanFor', rfr),\n",
    "                                 ('XGBoost', xgb)\n",
    "                                ],\n",
    "                     n_jobs=-1,\n",
    "                     weights=[4, 2, 3])\n",
    "    vr.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the yield\n",
    "    y_predVR = vr.predict(X_test)\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predVR)\n",
    "    plot.add('Voting Regression', y_test, y_predVR)'''\n",
    "    \n",
    "    from sklearn import linear_model\n",
    "    BR = linear_model.BayesianRidge()\n",
    "    BR.fit(X_train,y_train)\n",
    "    y1_reg=BR.predict(X_train)\n",
    "    y_predBRL = BR.predict(X_test)\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predBRL)\n",
    "    plot.add('Bayes', y_test, y_predBRL)\n",
    "    \n",
    "    # Fitting training set to SVR\n",
    "    from sklearn.svm import SVR\n",
    "    svr = SVR(kernel='rbf')\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_predSVR = svr.predict(X_test)\n",
    "    \n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predSVR)\n",
    "    plot.add('SVR', y_test, y_predSVR)\n",
    "    \n",
    "    # Fitting training set to lasso regression model\n",
    "    from sklearn.linear_model import Lasso\n",
    "    ls = Lasso(alpha =10)\n",
    "    ls.fit(X_train, y_train)\n",
    "\n",
    "    y_predlass = ls.predict(X_test)\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predlass)\n",
    "    plot.add('Lasso', y_test, y_predlass)\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    knr = KNeighborsRegressor(metric='minkowski', n_neighbors=5, n_jobs=-1)\n",
    "    knr.fit(X_train, y_train)\n",
    "\n",
    "    y_predknn = knr.predict(X_test)\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predknn)\n",
    "    plot.add('KNN', y_test, y_predknn)\n",
    "    \n",
    "    '''from gplearn.genetic import SymbolicRegressor\n",
    "    sr = SymbolicRegressor(n_jobs=-1, random_state=10, verbose=1, generations=100,\n",
    "                       function_set=('add', 'sub', 'max'))\n",
    "    sr.fit(X_train, y_train)\n",
    "\n",
    "    y_predSR = sr.predict(X_test)\n",
    "    CompareModels.R2AndRMSE(y_test=y_test, y_pred=y_predSR)\n",
    "    plot.add('Symbolic Regression', y_test, y_predSR)'''\n",
    "    \n",
    "    plot.show(figsize=(10, 5))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4163f-6359-446a-80bb-e4bd3e29400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from January\n",
    "#df_wbb2 = pd.read_csv('./wbb_740.csv')\n",
    "df_wbb2 = pd.read_csv('./wbb_740_2021months.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a05359-a7a8-43ef-b6f6-c8953025d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_wbb2.shape)\n",
    "df_wbb2 = df_wbb2.loc[df_wbb2['d_u'] != -9999]\n",
    "print(df_wbb2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40193d1b-11b4-4ea9-bda5-f67434f774b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gernerate list of interesting features\n",
    "feat_li = ['yo_', 'd_', 'xb_', 'xa_', 'stdev_']\n",
    "feat2_li = ['t','td','u','v','ws','rh'] \n",
    "nw_li = [st+ap for ap in feat2_li for st in feat_li ]\n",
    "feat_to_plot = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]\n",
    "df1 = df_wbb2[feat_to_plot]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1b03d-0036-45a1-bdf5-ff4c2581963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here pieces of code that are not used each time\n",
    "cor = df_wbb2[nw_li].corr()\n",
    "cor.style.background_gradient(cmap='coolwarm')\n",
    "######\n",
    "cor_extr = cor[[('d_'+str(j)) for j in ['t','td','u','v','ws','rh']]]\n",
    "####### histograms\n",
    "import seaborn as sns\n",
    "# This could be done in some way to bude able to export - create handler for sns.histplot.... separately export .. to pandas?\n",
    "#g = [('d_'+str(j)) for j in ['t','td','u','v','ws','rh']\n",
    "for i, col in enumerate(df1.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(df1[col],kde=True, stat=\"density\", linewidth=0, bins =10)\n",
    "    \n",
    "def histograms_plot(dataframe, features, rows, cols):\n",
    "    fig=plt.figure(figsize=(100,100))\n",
    "    for i, feature in enumerate(features):\n",
    "        ax=fig.add_subplot(rows,cols,i+1)\n",
    "        dataframe[feature].hist(bins=10,ax=ax,facecolor='green')\n",
    "        ax.set_title(feature+\" Distribution\",color='red')\n",
    "\n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "    return\n",
    "# histograms_plot(df1,df1.columns,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69e3b3-347a-4f4a-ad88-ff33e0325fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23d158-c454-419a-a47a-10c6b3521fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "test_dat = df1['d_t'].values\n",
    "f = Fitter(test_dat,\n",
    "           distributions=['gamma',\n",
    "                          'lognorm',\n",
    "                          \"beta\",\n",
    "                          \"burr\",\n",
    "                          \"norm\"])\n",
    "f.fit()\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ae4cc-7453-488a-8b29-245bb712ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_dists = Fitter(test_dat,distributions = get_common_distributions())\n",
    "f2_dists .fit()\n",
    "f2_dists .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a9dc3-e095-4b60-968e-b20ac6fcf8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ['sumsquare_error','aic','bic']:\n",
    "    params = f2_dists.get_best(method = m)\n",
    "    print('For {} parameter, best method is: {}'.format(m,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b2954-de7f-4514-95b1-fdb6b92a3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to get understand values of differences\n",
    "def create_shifts(df,periods,column_name_li):\n",
    "  #Creates shifts in periods for dataframe and names i.e. what is value in previous one or two terms?\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"sh_\" + str(periods)] = df[name_li].shift(periods = periods)\n",
    "    return df\n",
    "\n",
    "def create_differences(df,periods,column_name_li):\n",
    "    for name_li in column_name_li:\n",
    "        df[str(name_li) + \"dif_\" + str(periods)] = df[name_li].diff(periods = periods)\n",
    "    return df\n",
    "\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "      df_wbb2 = create_shifts(df_wbb2, tm_sp, df1.keys())\n",
    "\n",
    "for tm_sp in [1,2,3,4,5]:\n",
    "      df_wbb2 = create_differences(df_wbb2, tm_sp, df1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc00c9f-b5f6-44fc-8b41-2cdb440420dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of interestin, differences and shifts\n",
    "nw_li = nw_li + ['(Index) -> Time']\n",
    "for i in df_wbb2.keys():\n",
    "    if (\"sh_\" in i) or (\"dif_\" in i):\n",
    "        nw_li = nw_li + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef331aac-69c3-461d-80c5-db74d808a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df_wbb2[nw_li].corr()\n",
    "cor_dif = cor[['d_t','d_td','d_u','d_v','d_ws','d_rh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabb21f-403a-43d3-80f1-76a9cfa20872",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_td_hc = cor_dif['d_td'].loc[abs(cor_dif['d_td'])> 0.10]\n",
    "d_t_hc = cor_dif['d_t'].loc[abs(cor_dif['d_t'])> 0.10]\n",
    "d_rh_hc = cor_dif['d_rh'].loc[abs(cor_dif['d_rh'])> 0.10]\n",
    "d_u_hc = cor_dif['d_u'].loc[abs(cor_dif['d_u'])> 0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dff4e-5fbe-471a-b1b2-701ec236671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_err = df_wbb2.loc[abs(df_wbb2['d_v']) < 1]\n",
    "feature_set = ['d_v','d_vsh_1','d_vsh_2','d_vsh_3','d_vsh_4']\n",
    "no_err[feature_set].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407962e-bcb8-4ebe-8303-17bbed23431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot_preceding(df,column,err_val):\n",
    "    '''shows boxplot of chosen column when absolute value is smaller than err_val'''\n",
    "    no_err = df.loc[abs(df[column]) < err_val]\n",
    "    feature_set = [column,column + 'sh_1',column +'sh_2',column +'sh_3',column +'sh_4']\n",
    "    a = no_err[feature_set].boxplot()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd6eb0-01ec-4d68-bead-4e48bf51e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_larger_boxplot_preceding(df,column,err_val):\n",
    "    '''shows boxplot of chosen column when absolute value is Larger than err_val'''\n",
    "    no_err = df.loc[abs(df[column]) > err_val]\n",
    "    feature_set = [column,column + 'sh_1',column +'sh_2',column +'sh_3',column +'sh_4']\n",
    "    a = no_err[feature_set].boxplot()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e005ee-24a5-4f22-88ff-01e0e14d6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_larger_boxplot_preceding(df_wbb2,'d_t',2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8a21a-c472-419a-8a9c-ac33282159e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_err = df_wbb2.loc[abs(df_wbb2['d_t']) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c1a2d-75ca-43a9-969a-67df19168781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa575a-7cbf-4ea3-91f8-bfe6cc7a049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pairplot(df,features_li):\n",
    "    plot_df = df[features_li]\n",
    "    pp =sns.pairplot(plot_df)\n",
    "    return pp\n",
    "\n",
    "col_name = 'd_rh'\n",
    "no_err = df_wbb2.loc[abs(df_wbb2[col_name]) > 5]\n",
    "li = [col_name+x for x in ['','sh_1','sh_2','sh_3','sh_4' ]]\n",
    "print(li)\n",
    "show_pairplot(no_err,li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dad3d9-c61c-4c1b-ba4a-b00fdb431a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2['t_ddif_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f27a1-2f06-42af-b9dd-8001d471142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_corr_series(df,col,val):\n",
    "    #returns dataframe of correlation higher than val in column\n",
    "    cor = df.corr()\n",
    "    outp = cor[col].loc[abs(cor_dif[col])> val]\n",
    "    return outp\n",
    "\n",
    "cor_td = get_high_corr_series(df_wbb2[nw_li],'d_t',0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03239dbd-33e8-47c4-b5e1-20f229381a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x = no_err['d_td'].tolist()\n",
    "y1 = no_err['d_tdsh_1'].tolist()\n",
    "y2 = no_err['d_tdsh_2']\n",
    "y3 = no_err['d_tdsh_3']\n",
    "\n",
    "data = no_err['d_td','d_tdsh_1','d_tdsh_2']\n",
    "\n",
    "sns.regplot(x = \"d_td\", \n",
    "            y = 'd_tdsh_4', \n",
    "            data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908c709-0f42-47dc-8226-410e0ef09134",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5]:\n",
    "    df_wbb2 = create_differences(df_wbb2,i,['d_ws'])\n",
    "    df_wbb2 = create_shifts(df_wbb2,i,['d_ws'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f474eec7-6290-467b-9ad8-33c19af036c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbb2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0feb4-04a8-45b7-8408-18dbd2bc07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'yo_t', 'd_t', 'xb_t', 'xa_t', 'stdev_t', 'yo_td', 'd_td', 'xb_td',\n",
    "#       'xa_td', 'stdev_td', 'yo_u', 'd_u', 'xb_u', 'xa_u', 'stdev_u', 'yo_v',\n",
    "#       'd_v', 'xb_v', 'xa_v', 'stdev_v', 'yo_ws', 'd_ws', 'xb_ws', 'xa_ws',\n",
    "#       'stdev_ws', 'yo_rh', 'd_rh', 'xb_rh', 'xa_rh', 'stdev_rh'],\n",
    "#prep_df = df_wbb2[['yo_tdsh_1','d_td','d_tddif_1', 'd_tddif_2', 'd_tddif_3', 'd_tddif_4']].dropna()\n",
    "#prep_df = df_wbb2[['d_ws','d_wsdif_1', 'd_wsdif_2', 'd_wsdif_3', 'd_wsdif_4','d_wssh_2', 'd_wssh_3', 'd_wssh_4']].dropna()\n",
    "prep_df = df_wbb2[['d_ws', 'd_wsdif_3', 'd_wsdif_4','d_wsdif_5']].dropna()\n",
    "#prep_df['d_t'] = pd.cut(prep_df.d_t, [-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], labels= [-9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "X = prep_df[[ 'd_wsdif_3', 'd_wsdif_4','d_wsdif_5']]\n",
    "#X = prep_df [[ 'd_tdsh_2', 'd_tdsh_3', 'd_tdsh_4', 'd_tdsh_4']]\n",
    "#X = prep_df [[ 'd_tddif_1', 'd_tddif_2', 'd_tddif_3', 'd_tddif_4']]\n",
    "y = prep_df['d_ws']\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "#convert y values to categorical values\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(y)\n",
    "#y_transformed = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5efe66-b099-4f92-a6b6-d00c9c608679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b80a7a-cbd3-4d40-b80d-7bf45f30cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = show_linear_comparison(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7979faa-0039-486a-9bdf-9fa6a2bced49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api yyas sm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "#Linear regression, Bayesian Regression, Lasso\n",
    "X_Train=X_train.values\n",
    "X_Train=np.asarray(X_Train)\n",
    "#https://www.kaggle.com/code/ankitjha/comparing-regression-models\n",
    "# Finding normalised array of X_Train\n",
    "sc = StandardScaler()\n",
    "X_std=sc.fit_transform(X_Train)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(X_std)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0,7,1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d2c93-ca82-4419-801d-937da914b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REGRESSION BAYES\n",
    "#######\n",
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(X_train,y_train)\n",
    "y1_reg=reg.predict(X_train)\n",
    "y1_reg=list(y1_reg)\n",
    "y2_reg=reg.predict(X_test)\n",
    "y2_reg=list(y2_reg)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_reg[i]-y_train[i])/y_train[i])\n",
    "train_error_bay=error/len(y_train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_bay)+\" percent\"+\" in Bayesian Regression\")\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y2_reg[i]-y_test[i])/y_test[i])\n",
    "test_error_bay=(error/len(y_test))*100\n",
    "print(\"Test error = \"+'{}'.format(test_error_bay)+\" percent\"+\" in Bayesian Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917ea7e-e3d2-4b34-96d7-8e4c266ff63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2b2e3-930b-4f34-9d8f-acf3acfa50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.BayesianRidge(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12726623-5ee1-4f76-a70d-b8274a87aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a0658-da0a-4c00-b6f8-1bdc683d8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb315d1-c950-41e7-9d20-4c86a4549285",
   "metadata": {},
   "outputs": [],
   "source": [
    "vysl = clf.score(X_train, y_train, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d1e9e-46a0-4f30-b21a-92b46b39cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vysl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e668a-140e-4800-a31b-6f89afe2983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ard = linear_model.ARDRegression(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b4e93c-e3a3-473c-9002-62b1691f99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ard.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6823b91-2fd8-4bd8-9209-4c4e69298338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/58217005/how-to-reverse-label-encoder-from-sklearn-for-multiple-columns\n",
    "inverted = lab.inverse_transform(y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30534e7a-99da-46d9-aad2-2306fe57c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPrice = pd.DataFrame(clf.predict(X_test), columns=['Predicted Price']) # Create new dataframe of column'Predicted Price'\n",
    "actualPrice = pd.DataFrame(y_test, columns=['Actual Price'])\n",
    "actualPrice = actualPrice.reset_index(drop=True) # Drop the index so that we can concat it, to create new dataframe\n",
    "df_actual_vs_predicted = pd.concat([actualPrice,predictedPrice],axis =1)\n",
    "df_actual_vs_predicted.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561376d4-29f3-49bf-a809-c8a3e3dacc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pl = clf.predict(X_test)\n",
    "y_pl = y_test\n",
    "#minmaxscaler - use original data a neco vyleze, vlastne je jedno co to ted bude\n",
    "scal = MinMax\n",
    "plt.scatter(y_pl, clf.predict(X_test))\n",
    "#plt.scatter(y_test, clf.predict(X_test))\n",
    "plt.xlabel('ValFrom Dataset')\n",
    "plt.ylabel('Val Predicted By Model')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6) # Custom figure size in inches\n",
    "plt.title(\"OBS Dataset Vs  Predicted By Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834cb447-ab9b-49e0-8835-72b4b4b5e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pl.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7e1c3-b26c-44ee-9718-71b55f81622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lab.inverse_transform(y_test)\n",
    "b = sc.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f2e7a-5336-425f-9ffd-43f7454ae17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a55b67-69f6-41af-a93f-fecff42f27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(a, b)\n",
    "#plt.scatter(y_test, clf.predict(X_test))\n",
    "plt.xlabel('ValFrom Dataset')\n",
    "plt.ylabel('Val Predicted By Model')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6) # Custom figure size in inches\n",
    "plt.title(\"OBS Dataset Vs  Predicted By Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9fcb0-3a44-4f45-a70c-7b837a4df7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vysl = ard.score(X_train, y_train, sample_weight=None)\n",
    "print(vysl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91dfd7-250e-4c99-9cf5-6f08df27e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc7a23-6fdc-4ddc-8e45-b149c55be4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc116e-c1df-4403-adc7-5af302d1cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=full_data, x=\"input_feature\", y=\"target\", color=\"black\", alpha=0.75\n",
    ")\n",
    "ax.plot(X, y_plot, color=\"black\", label=\"Ground Truth\")\n",
    "ax.plot(X, y_brr, color=\"red\", label=\"BayesianRidge with polynomial features\")\n",
    "ax.plot(X, y_ard, color=\"navy\", label=\"ARD with polynomial features\")\n",
    "ax.fill_between(\n",
    "    X_plot.ravel(),\n",
    "    y_ard - y_ard_std,\n",
    "    y_ard + y_ard_std,\n",
    "    color=\"navy\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax.fill_between(\n",
    "    X_plot.ravel(),\n",
    "    y_brr - y_brr_std,\n",
    "    y_brr + y_brr_std,\n",
    "    color=\"red\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "ax.legend()\n",
    "_ = ax.set_title(\"Polynomial fit of a non-linear feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9365ec-0d75-4696-a821-c5edca71e6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf812f-3d13-41ba-828e-483ec72e8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_Train, y_Test= X_Train, X_test,y_train, y_test\n",
    "model=linear_model.Ridge()\n",
    "model.fit(x_train,y_train)\n",
    "y_predict=model.predict(x_train)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_Train)):\n",
    "    error+=(abs(y_Train[i]-y_predict[i])/y_Train[i])\n",
    "train_error_ridge=error/len(y_Train)*100\n",
    "print(\"Train error = \"'{}'.format(train_error_ridge)+\" percent in Ridge Regression\")\n",
    "\n",
    "Y_test=model.predict(x_test)\n",
    "y_Predict=list(y_test)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y_Predict[i]-Y_test[i])/y_Predict[i])\n",
    "test_error_ridge=error/len(Y_test)*100\n",
    "print(\"Test error = \"'{}'.format(test_error_ridge)+\" percent in Ridge Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab9c34-4d9a-4432-bc5e-d886d3ed71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":model.predict(x_train), \"true\":y_train})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in Ridge Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f31e36-6678-4e99-b98e-bfce861c71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors=8\n",
    "knn=neighbors.KNeighborsRegressor(n_neighbors,weights='uniform')\n",
    "knn.fit(x_train,y_train)\n",
    "y1_knn=knn.predict(x_train)\n",
    "y1_knn=list(y1_knn)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_knn[i]-y_Train[i])/y_Train[i])\n",
    "train_error_knn=error/len(y_Train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_knn)+\" percent\"+\" in Knn algorithm\")\n",
    "\n",
    "y2_knn=knn.predict(x_test)\n",
    "y2_knn=list(y2_knn)\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y2_knn[i]-Y_test[i])/Y_test[i])\n",
    "test_error_knn=error/len(Y_test)*100\n",
    "print(\"Test error = \"'{}'.format(test_error_knn)+\" percent\"+\" in knn algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f96b8-8a96-40af-bb20-dc6cf50e4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":knn.predict(x_train), \"true\":y_train})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in Knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2fcd7-5d95-4f55-9990-09a3815f679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(x_train,y_train)\n",
    "y1_reg=reg.predict(x_train)\n",
    "y1_reg=list(y1_reg)\n",
    "y2_reg=reg.predict(x_test)\n",
    "y2_reg=list(y2_reg)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_reg[i]-y_Train[i])/y_Train[i])\n",
    "train_error_bay=error/len(y_Train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_bay)+\" percent\"+\" in Bayesian Regression\")\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y2_reg[i]-Y_test[i])/Y_test[i])\n",
    "test_error_bay=(error/len(Y_test))*100\n",
    "print(\"Test error = \"+'{}'.format(test_error_bay)+\" percent\"+\" in Bayesian Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b153c-87e7-4f8a-828e-80d80ed56b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":reg.predict(x_train), \"true\":y_train})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in Bayesian Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03212259-b156-4483-9b52-3a9116fc8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dec = tree.DecisionTreeRegressor(max_depth=1)\n",
    "dec.fit(x_train,y_train)\n",
    "y1_dec=dec.predict(x_train)\n",
    "y1_dec=list(y1_dec)\n",
    "y2_dec=dec.predict(x_test)\n",
    "y2_dec=list(y2_dec)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_dec[i]-y_Train[i])/y_Train[i])\n",
    "train_error_tree=error/len(y_Train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_tree)+\" percent\"+\" in Decision Tree Regressor\")\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y1_dec[i]-Y_test[i])/Y_test[i])\n",
    "test_error_tree=error/len(Y_test)*100\n",
    "print(\"Test error = \"'{}'.format(test_error_tree)+\" percent in Decision Tree Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54889eec-7a3a-4c06-8ed0-3a395aa2947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":dec.predict(x_train), \"true\":y_train})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b034b4-e7a1-4996-bc2f-e3f42c1e1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg=svm.SVR()\n",
    "svm_reg.fit(x_train,y_train)\n",
    "y1_svm=svm_reg.predict(x_train)\n",
    "y1_svm=list(y1_svm)\n",
    "y2_svm=svm_reg.predict(x_test)\n",
    "y2_svm=list(y2_svm)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_svm[i]-y_Train[i])/y_Train[i])\n",
    "train_error_svm=error/len(y_Train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_svm)+\" percent\"+\" in SVM Regressor\")\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y2_svm[i]-Y_test[i])/Y_test[i])\n",
    "test_error_svm=error/len(Y_test)*100\n",
    "print(\"Test error = \"'{}'.format(test_error_svm)+\" percent in SVM Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003899c0-5076-4d35-b3a8-c834626c3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "preds = pd.DataFrame({\"preds\":knn.predict(x_train), \"true\":y_train})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\"Residual plot in SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996c3e6-777b-4802-8483-2b9cca7b7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 300 ,  random_state = 0)\n",
    "rf_regressor.fit(x_train,y_train)\n",
    "#Predicting the SalePrices using test set \n",
    "\n",
    "y1_svm=rf_regressor.predict(x_train)\n",
    "y1_svm=list(y1_svm)\n",
    "y2_svm=rf_regressor.predict(x_test)\n",
    "y2_svm=list(y2_svm)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_svm[i]-y_Train[i])/y_Train[i])\n",
    "train_error_rf=error/len(y_Train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_rf)+\" percent\"+\" in RF Regressor\")\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y2_svm[i]-Y_test[i])/Y_test[i])\n",
    "test_error_rf=error/len(Y_test)*100\n",
    "print(\"Test error = \"'{}'.format(test_error_rf)+\" percent in RF Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9da6ee-ab5a-4a55-80f9-4f89a99b9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error=[train_error_ridge,train_error_knn,train_error_bay,train_error_tree,train_error_svm,train_error_rf]\n",
    "test_error=[test_error_ridge,test_error_knn,test_error_bay,test_error_tree,test_error_svm,test_error_rf]\n",
    "\n",
    "col={'Train Error':train_error,'Test Error':test_error}\n",
    "models=['Ridge Regression','Knn','Bayesian Regression','Decision Tree','SVM','RF']\n",
    "df_output=DataFrame(data=col,index=models)\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b4cd8-68e1-4855-8978-72a60f89726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = df_wbb2.plot(kind='scatter', x='d_t', y='d_tsh_2', color='r')\n",
    "ax3 = df_wbb2.plot(kind='scatter', x='d_t', y='d_tsh_3', color='g', ax = ax2)\n",
    "ax4 = df_wbb2.plot(kind='scatter', x='d_t', y='d_tsh_4', color='b', ax = ax2)\n",
    "ax5 = df_wbb2.plot(kind='scatter', x='d_t', y='d_tsh_5', color='k', ax = ax2)\n",
    "print(ax2 == ax3 ==ax4 ==ax5)\n",
    "# https://stackoverflow.com/questions/43061768/plotting-multiple-scatter-plots-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f012be-bb22-4b44-86f5-6d9195392175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMTERE TUNING\n",
    "# installing library for Bayesian optimization\n",
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef841c56-9639-4abf-a2b9-4b67fc1c1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "def model_gp_function(X_train_sample, y_train_sample):\n",
    "    '''\n",
    "    Learn posteriori Gaussian Process Regression model using sample data set X_train_sample/y_train_sample\n",
    "    Attributes\n",
    "    -------\n",
    "      X_train_sample: chosen training set (sampling points for which we have already calculated the value of the black box function)\n",
    "      y_train_sample: target values in chosen training set ( already calculated values of the black-box function)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    GP model\n",
    "    '''\n",
    "\n",
    "    # Define the kernel and GP regressor\n",
    "    kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3))\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, random_state=2)\n",
    "    \n",
    "    # Train model using X_train_sample and y_train_sample\n",
    "    gpr.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "    return gpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d0bde-bb27-47ac-a608-54e56e55e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gp_function(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed81566-e129-42e9-b93a-d8ee92731f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_gp_function(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57d9e6-97e1-4e9f-9850-2e28f21881d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = a\n",
    "rf_regressor.fit(x_train,y_train)\n",
    "#Predicting the SalePrices using test set \n",
    "\n",
    "y1_svm=rf_regressor.predict(x_train)\n",
    "y1_svm=list(y1_svm)\n",
    "y2_svm=rf_regressor.predict(x_test)\n",
    "y2_svm=list(y2_svm)\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_train)):\n",
    "    error+=(abs(y1_svm[i]-y_Train[i])/y_Train[i])\n",
    "train_error_rf=error/len(y_Train)*100\n",
    "print(\"Train error = \"+'{}'.format(train_error_rf)+\" percent\"+\" in Gaus Regressor\")\n",
    "\n",
    "error=0\n",
    "for i in range(len(y_test)):\n",
    "    error+=(abs(y2_svm[i]-Y_test[i])/Y_test[i])\n",
    "test_error_rf=error/len(Y_test)*100\n",
    "print(\"Test error = \"'{}'.format(test_error_rf)+\" percent in Gaus Regressor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb675-0fcf-4bf4-8ea7-663a15fb79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= pd.pivot_table(df_wbb2, values='Count', index='d_t', columns='d_tdif_2')\n",
    "sns.heatmap(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57138afd-be78-48da-aef0-fc3bd22f3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax2 = df_wbb2.plot(kind='scatter', x='d_ws', y='d_wssh_2', color='r')\n",
    "#ax3 = df_wbb2.plot(kind='scatter', x='d_ws', y='d_wssh_3', color='g')\n",
    "#ax4 = df_wbb2.plot(kind='scatter', x='d_ws', y='d_wssh_4', color='b')\n",
    "#ax5 = df_wbb2.plot(kind='scatter', x='d_ws', y='d_wssh_5', color='k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
